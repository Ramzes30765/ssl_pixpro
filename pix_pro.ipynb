{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kitt/ssl_pixpro/.ssl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.attention import flex_attention\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import timm\n",
    "from clearml import Task, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reg_parameters import register_all_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-07 21:32:57,360 - clearml.Repository Detection - WARNING - Could not read Jupyter Notebook: No module named 'nbconvert'\n",
      "2025-03-07 21:32:57,361 - clearml.Repository Detection - WARNING - Please install nbconvert using \"pip install nbconvert\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not read Jupyter Notebook: No module named 'nbconvert'\n",
      "Please install nbconvert using \"pip install nbconvert\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=4c5751e27b194db79c93558a91c7abf7\n",
      "ClearML results page: http://10.0.10.7:8085/projects/201646de8d454f79b01ceb0a33cb1863/experiments/4c5751e27b194db79c93558a91c7abf7/output/log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEARML-SERVER new package available: UPGRADE to v2.0.0 is recommended!\n",
      "Release Notes:\n",
      "### Breaking Changes\n",
      "\n",
      "MongoDB major version was upgraded from v5.x to 6.x.\n",
      "Please note that if your current ClearML Server version is smaller than v1.17 (where MongoDB v5.x was first used), you'll need to first upgrade to ClearML Server v1.17.\n",
      "#### Upgrading to ClearML Server v1.17 from a previous version\n",
      "- If using docker-compose,  use the following docker-compose files:\n",
      "  * [docker-compose file](https://github.com/allegroai/clearml-server/blob/2976ce69cc91550a3614996e8a8d8cd799af2efd/upgrade/1_17_to_2_0/docker-compose.yml)\n",
      "  * [docker-compose file foe Windows](https://github.com/allegroai/clearml-server/blob/2976ce69cc91550a3614996e8a8d8cd799af2efd/upgrade/1_17_to_2_0/docker-compose-win10.yml)\n",
      "\n",
      "### New Features\n",
      "\n",
      "- New look and feel: Full light/dark themes ([clearml #1297](https://github.com/allegroai/clearml/issues/1297))\n",
      "- New UI task creation options\n",
      "  - Support bash as well as python scripts\n",
      "  - Support file upload\n",
      "- New UI setting for configuring cloud storage credentials with which ClearML can clean up cloud storage artifacts on task deletion. \n",
      "- Add UI scalar plots presentation of plots in sections grouped by metrics.\n",
      "- Add UI Batch export plot embed codes for all metric plots in a single click.\n",
      "- Add UI pipeline presentation of steps grouped into stages\n",
      "\n",
      "### Bug Fixes\n",
      "- Fix UI Model Endpoint's Number of Requests plot sometimes displays incorrect data\n",
      "- Fix UI datasets page does not filter according to project when dataset is running \n",
      "- Fix UI task scalar legend does not change colors when smoothing is enabled \n",
      "- Fix queue list in UI Workers and Queues page does not alphabetically sort by queue display name \n",
      "- Fix queue display name is not searchable in UI Task Creation modal's queue field\n",
      "\n",
      "ClearML Task: created new task id=4c5751e27b194db79c93558a91c7abf7\n",
      "ClearML results page: http://10.0.10.7:8085/projects/201646de8d454f79b01ceb0a33cb1863/experiments/4c5751e27b194db79c93558a91c7abf7/output/log\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(task_name='123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_size': 640, 'dataset_name': 'ssl_turbine_dataset', 'train_folder': 'turbine_train', 'val_folder': 'turbine_val', 'batchsize': 32, 'numworkers': 16}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.to_container(cfg, resolve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_all_parameters(task, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = task.get_parameters_as_dict()['General']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data.batchsize': '32',\n",
       " 'data.dataset_name': 'ssl_turbine_dataset',\n",
       " 'data.img_size': '640',\n",
       " 'data.numworkers': '16',\n",
       " 'data.train_folder': 'turbine_train',\n",
       " 'data.val_folder': 'turbine_val',\n",
       " 'model.backbone': 'resnet18',\n",
       " 'model.predictor_blocks': '1',\n",
       " 'model.pretrained': 'False',\n",
       " 'model.projector_blocks': '1',\n",
       " 'model.reduction': '4',\n",
       " 'pipeline.pipe_name': 'SSL pipeline',\n",
       " 'pipeline.pipe_proj_name': 'PixPro',\n",
       " 'pipeline.queue': 'pixpro_queue',\n",
       " 'task.proj_name': 'PixPro',\n",
       " 'task.task_name': 'ResNet',\n",
       " 'train.accelerator': 'auto',\n",
       " 'train.devices': 'auto',\n",
       " 'train.epoch': '1',\n",
       " 'train.log_step': '5',\n",
       " 'train.lr_end': '1e-05',\n",
       " 'train.lr_start': '0.001',\n",
       " 'train.val_step': '10',\n",
       " 'val.eps': '0.5',\n",
       " 'val.min_samples': '5',\n",
       " 'val.sample_fraction': '1.0'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_omegaconf(original_dict):\n",
    "\n",
    "    def parse_value(value_str):\n",
    "        try:\n",
    "            return eval(value_str)  # Ïðåîáðàçóåò \"False\" > False, \"1e-5\" > 0.00001\n",
    "        except:\n",
    "            return value_str\n",
    "\n",
    "    nested_dict = {}\n",
    "    for key, value in original_dict.items():\n",
    "        # new_key = key.replace(\"General/\", \"\")\n",
    "        parts = key.split(\".\")\n",
    "        current_level = nested_dict\n",
    "        for part in parts[:-1]:\n",
    "            if part not in current_level:\n",
    "                current_level[part] = {}\n",
    "            current_level = current_level[part]\n",
    "        current_level[parts[-1]] = parse_value(value)\n",
    "\n",
    "    return OmegaConf.create(nested_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas = dict_to_omegaconf(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accelerator': 'auto', 'devices': 'auto', 'epoch': 1, 'log_step': 5, 'lr_end': 1e-05, 'lr_start': 0.001, 'val_step': 10}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pas.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconfig = OmegaConf.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'General/pipeline.pipe_name': 'SSL pipeline', 'General/pipeline.pipe_proj_name': 'PixPro', 'General/task.proj_name': 'PixPro', 'General/task.task_name': 'ResNet', 'General/model.backbone': 'resnet18', 'General/model.pretrained': 'False', 'General/model.projector_blocks': '1', 'General/model.predictor_blocks': '1', 'General/model.reduction': '4', 'General/data.img_size': '640', 'General/data.dataset_name': 'ssl_turbine_dataset', 'General/data.train_folder': 'turbine_train', 'General/data.val_folder': 'turbine_val', 'General/data.batchsize': '32', 'General/data.numworkers': '16', 'General/train.epoch': '1', 'General/train.lr_start': '0.001', 'General/train.lr_end': '1e-05', 'General/train.devices': 'auto', 'General/train.accelerator': 'auto', 'General/train.val_step': '10', 'General/train.log_step': '5', 'General/val.eps': '0.5', 'General/val.min_samples': '5', 'General/val.sample_fraction': '1.0', 'General/pipeline.queue': 'pixpro_queue'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigAttributeError",
     "evalue": "Missing key data\n    full_key: data\n    object_type=dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigAttributeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mbatchsize\n",
      "File \u001b[0;32m~/ssl_pixpro/.ssl/lib/python3.10/site-packages/omegaconf/dictconfig.py:355\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_impl(\n\u001b[1;32m    352\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, default_value\u001b[38;5;241m=\u001b[39m_DEFAULT_MARKER_, validate_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     )\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfigAttributeError\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/ssl_pixpro/.ssl/lib/python3.10/site-packages/omegaconf/base.py:231\u001b[0m, in \u001b[0;36mNode._format_and_raise\u001b[0;34m(self, key, value, cause, msg, type_override)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_format_and_raise\u001b[39m(\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    225\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     type_override: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     \u001b[43mformat_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/ssl_pixpro/.ssl/lib/python3.10/site-packages/omegaconf/_utils.py:899\u001b[0m, in \u001b[0;36mformat_and_raise\u001b[0;34m(node, key, value, msg, cause, type_override)\u001b[0m\n\u001b[1;32m    896\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type \u001b[38;5;241m=\u001b[39m ref_type\n\u001b[1;32m    897\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type_str \u001b[38;5;241m=\u001b[39m ref_type_str\n\u001b[0;32m--> 899\u001b[0m \u001b[43m_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ssl_pixpro/.ssl/lib/python3.10/site-packages/omegaconf/_utils.py:797\u001b[0m, in \u001b[0;36m_raise\u001b[0;34m(ex, cause)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     ex\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/ssl_pixpro/.ssl/lib/python3.10/site-packages/omegaconf/dictconfig.py:351\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m()\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_MARKER_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(\n\u001b[1;32m    356\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me, type_override\u001b[38;5;241m=\u001b[39mConfigAttributeError\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m~/ssl_pixpro/.ssl/lib/python3.10/site-packages/omegaconf/dictconfig.py:442\u001b[0m, in \u001b[0;36mDictConfig._get_impl\u001b[0;34m(self, key, default_value, validate_key)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_impl\u001b[39m(\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m, key: DictKeyType, default_value: Any, validate_key: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m         node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_child\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_key\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (ConfigAttributeError, ConfigKeyError):\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m default_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _DEFAULT_MARKER_:\n",
      "File \u001b[0;32m~/ssl_pixpro/.ssl/lib/python3.10/site-packages/omegaconf/basecontainer.py:73\u001b[0m, in \u001b[0;36mBaseContainer._get_child\u001b[0;34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_child\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     throw_on_missing_key: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Optional[Node], List[Optional[Node]]]:\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Like _get_node, passing through to the nearest concrete Node.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrow_on_missing_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_on_missing_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, UnionNode) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_special(child):\n\u001b[1;32m     81\u001b[0m         value \u001b[38;5;241m=\u001b[39m child\u001b[38;5;241m.\u001b[39m_value()\n",
      "File \u001b[0;32m~/ssl_pixpro/.ssl/lib/python3.10/site-packages/omegaconf/dictconfig.py:480\u001b[0m, in \u001b[0;36mDictConfig._get_node\u001b[0;34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m throw_on_missing_key:\n\u001b[0;32m--> 480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConfigKeyError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m throw_on_missing_value \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39m_is_missing():\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingMandatoryValue(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing mandatory value: $KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mConfigAttributeError\u001b[0m: Missing key data\n    full_key: data\n    object_type=dict"
     ]
    }
   ],
   "source": [
    "reconfig.data.batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'General/pipeline.pipe_name': 'SSL pipeline',\n",
       " 'General/pipeline.pipe_proj_name': 'PixPro',\n",
       " 'General/task.proj_name': 'PixPro',\n",
       " 'General/task.task_name': 'ResNet',\n",
       " 'General/model.backbone': 'resnet18',\n",
       " 'General/model.pretrained': 'False',\n",
       " 'General/model.projector_blocks': '1',\n",
       " 'General/model.predictor_blocks': '1',\n",
       " 'General/model.reduction': '4',\n",
       " 'General/data.img_size': '640',\n",
       " 'General/data.dataset_name': 'ssl_turbine_dataset',\n",
       " 'General/data.train_folder': 'turbine_train',\n",
       " 'General/data.val_folder': 'turbine_val',\n",
       " 'General/data.batchsize': '32',\n",
       " 'General/data.numworkers': '16',\n",
       " 'General/train.epoch': '1',\n",
       " 'General/train.lr_start': '0.001',\n",
       " 'General/train.lr_end': '1e-05',\n",
       " 'General/train.devices': 'auto',\n",
       " 'General/train.accelerator': 'auto',\n",
       " 'General/train.val_step': '10',\n",
       " 'General/train.log_step': '5',\n",
       " 'General/val.eps': '0.5',\n",
       " 'General/val.min_samples': '5',\n",
       " 'General/val.sample_fraction': '1.0',\n",
       " 'General/pipeline.queue': 'pixpro_queue'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet18'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.get('General/model.backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dict(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline': {'pipe_name': 'SSL pipeline', 'pipe_proj_name': 'PixPro'},\n",
       " 'task': {'proj_name': 'PixPro', 'task_name': 'ResNet'},\n",
       " 'model': {'backbone': 'resnet18', 'pretrained': False, 'projector_blocks': 1, 'predictor_blocks': 1, 'reduction': 4},\n",
       " 'data': {'img_size': 640, 'dataset_name': 'ssl_turbine_dataset', 'train_folder': 'turbine_train', 'val_folder': 'turbine_val', 'batchsize': 32, 'numworkers': 16},\n",
       " 'train': {'epoch': 1, 'lr_start': 0.001, 'lr_end': 1e-05, 'devices': 'auto', 'accelerator': 'auto', 'val_step': 10, 'log_step': 5},\n",
       " 'val': {'eps': 0.5, 'min_samples': 5, 'sample_fraction': 1.0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline': {'pipe_name': 'SSL pipeline', 'pipe_proj_name': 'PixPro'},\n",
       " 'task': {'proj_name': 'PixPro', 'task_name': 'ResNet'},\n",
       " 'model': {'backbone': 'resnet18', 'pretrained': False, 'projector_blocks': 1, 'predictor_blocks': 1, 'reduction': 4},\n",
       " 'data': {'img_size': 640, 'dataset_name': 'ssl_turbine_dataset', 'train_folder': 'turbine_train', 'val_folder': 'turbine_val', 'batchsize': 32, 'numworkers': 16},\n",
       " 'train': {'epoch': 1, 'lr_start': 0.001, 'lr_end': 1e-05, 'devices': 'auto', 'accelerator': 'auto', 'val_step': 10, 'log_step': 5},\n",
       " 'val': {'eps': 0.5, 'min_samples': 5, 'sample_fraction': 1.0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.connect_configuration(dict(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cfg = task.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "new_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelPropagationModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=4):\n",
    "\n",
    "        super(PixelPropagationModule, self).__init__()\n",
    "        self.inter_channels = in_channels // reduction\n",
    "        self.query_conv = nn.Conv2d(in_channels, self.inter_channels, kernel_size=1)\n",
    "        self.key_conv   = nn.Conv2d(in_channels, self.inter_channels, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        proj_query = self.query_conv(x).view(B, self.inter_channels, -1).permute(0, 2, 1)  # [B, H*W, C]\n",
    "        proj_key   = self.key_conv(x).view(B, self.inter_channels, -1) # [B, C, H*W]\n",
    "        score = torch.bmm(proj_query, proj_key) # [B, H*W, H*W]\n",
    "        attention = F.softmax(score, dim=-1) # [B, H*W, H*W]\n",
    "        proj_value = self.value_conv(x).view(B, C, -1) # [B, C, H*W]\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1)) # transpose attention - [B, C, H*W]\n",
    "        out = out.view(B, C, H, W)\n",
    "        out = self.gamma * out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexAttentionPPM(nn.Module):\n",
    "    def __init__(self, in_channels, dropout_p=0.0, is_causal=False):\n",
    "\n",
    "        super(FlexAttentionPPM, self).__init__()\n",
    "        # Проекция для формирования Q, K, V в один шаг\n",
    "        self.qkv_proj = nn.Conv2d(in_channels, in_channels * 3, kernel_size=1)\n",
    "        self.dropout_p = dropout_p\n",
    "        self.is_causal = is_causal\n",
    "        # Обучаемый коэффициент для остаточного соединения\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, C, H, W = x.size()\n",
    "        qkv = self.qkv_proj(x)\n",
    "        q, k, v = torch.chunk(qkv, chunks=3, dim=1)  # каждый [B, C, H, W]\n",
    "        \n",
    "        q = q.view(B, C, -1).permute(0, 2, 1)  # [B, H*W, C]\n",
    "        k = k.view(B, C, -1).permute(0, 2, 1)  # [B, H*W, C]\n",
    "        v = v.view(B, C, -1).permute(0, 2, 1)  # [B, H*W, C]\n",
    "        \n",
    "        attn_out = flex_attention(query=q, key=k, value=v, \n",
    "                                  attn_mask=None,\n",
    "                                  dropout_p=self.dropout_p,\n",
    "                                  is_causal=self.is_causal)\n",
    "\n",
    "        attn_out = attn_out.permute(0, 2, 1).view(B, C, H, W)\n",
    "        out = self.gamma * attn_out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = timm.create_model('resnet18', pretrained=False, features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixPro(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone_name,\n",
    "                 pretrained=False\n",
    "                 ):\n",
    "\n",
    "        super(PixPro, self).__init__()\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, features_only=True)\n",
    "        self.in_features = self.backbone(torch.randn(1, 3, 1024, 768))[-1].shape[1]\n",
    "        self.proj_dim = self.in_features * 4\n",
    "        self.hidden_dim = self.in_features // 4\n",
    "        \n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Conv2d(self.in_features, self.proj_dim, kernel_size=1),\n",
    "            nn.BatchNorm2d(self.proj_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(self.proj_dim, self.proj_dim, kernel_size=1)\n",
    "        )\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Conv2d(self.proj_dim, self.hidden_dim, kernel_size=1),\n",
    "            nn.BatchNorm2d(self.hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(self.hidden_dim, self.proj_dim, kernel_size=1)\n",
    "        )\n",
    "        self.pixel_propagation = PixelPropagationModule(self.proj_dim, reduction=4)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        f1 = self.backbone(x1)[-1]  # [B, in_features, H, W]\n",
    "        f2 = self.backbone(x2)[-1]\n",
    "        \n",
    "        z1 = self.projector(f1)     # [B, proj_dim, H, W]\n",
    "        z2 = self.projector(f2)\n",
    "        \n",
    "        p1 = self.predictor(z1)     # Предсказания (ветвь, по которой обновляются веса)\n",
    "        p2 = self.predictor(z2)\n",
    "        \n",
    "        y1 = self.pixel_propagation(z1)  # Целевые представления (для target)\n",
    "        y2 = self.pixel_propagation(z2)\n",
    "        \n",
    "        return p1, p2, y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixpro_loss(p1, p2, y1, y2):\n",
    "    # Flatten по пространственным измерениям: [B, proj_dim, H, W] -> [B, proj_dim, H*W]\n",
    "    p1_flat = p1.flatten(2)\n",
    "    p2_flat = p2.flatten(2)\n",
    "    y1_flat = y1.flatten(2)\n",
    "    y2_flat = y2.flatten(2)\n",
    "    # Вычисляем негативное косинусное сходство\n",
    "    loss1 = -F.cosine_similarity(p1_flat, y2_flat.detach(), dim=1).mean()\n",
    "    loss2 = -F.cosine_similarity(p2_flat, y1_flat.detach(), dim=1).mean()\n",
    "    return 0.5 * (loss1 + loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_augmentations(image_tensor):\n",
    "\n",
    "    pil_img = transforms.ToPILImage()(image_tensor)\n",
    "    \n",
    "    augmentation = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.0), ratio=(0.75, 1.33)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),\n",
    "        # (Опционально) Solarize: можно раскомментировать, если эксперименты показывают пользу\n",
    "        # transforms.RandomSolarize(threshold=128, p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        # Нормализация, если используется предобученный backbone с ImageNet нормализацией\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return augmentation(pil_img)\n",
    "\n",
    "def batch_augmentations(batch_images):\n",
    "    \"\"\"\n",
    "    Принимает батч изображений в виде тензора [B, C, H, W] и возвращает батч аугментированных изображений.\n",
    "    \"\"\"\n",
    "    augmented_images = []\n",
    "    for img in batch_images:\n",
    "        augmented_images.append(advanced_augmentations(img))\n",
    "    return torch.stack(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pixpro(model, dataloader, optimizer, device, epoch, augment_fn=batch_augmentations):\n",
    "    \"\"\"\n",
    "    Обучает модель PixPro на одной эпохе.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    task = Task.current_task()\n",
    "    for batch_idx, (images, _) in enumerate(dataloader):\n",
    "        x1 = augment_fn(images.clone())\n",
    "        x2 = augment_fn(images.clone())\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        p1, p2, y1, y2 = model(x1, x2)\n",
    "        loss = pixpro_loss(p1, p2, y1, y2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch {epoch} Batch {batch_idx}/{len(dataloader)} Loss: {loss.item():.4f}\")\n",
    "            task.get_logger().report_scalar(\"Training\", \"Loss\", iteration=epoch * len(dataloader) + batch_idx, value=loss.item())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"=== Epoch {epoch} Average Loss: {avg_loss:.4f} ===\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dense_features_global(model, dataloader, device, sample_fraction=1.0):\n",
    "    \"\"\"\n",
    "    Извлекает dense признаки для всего датасета: из последней карты признаков, преобразованной в форму [B*H*W, C].\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            feat_maps = model.backbone(images)[-1]  # [B, C, H, W]\n",
    "            feat_maps = F.normalize(feat_maps, p=2, dim=1)\n",
    "            B, C, H, W = feat_maps.shape\n",
    "            features = feat_maps.view(B, C, -1).permute(0, 2, 1).contiguous().view(-1, C)\n",
    "            if sample_fraction < 1.0:\n",
    "                num_samples = int(features.size(0) * sample_fraction)\n",
    "                idx = torch.randperm(features.size(0))[:num_samples]\n",
    "                features = features[idx]\n",
    "            all_features.append(features.cpu().numpy())\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_clustering_dbscan(model, dataloader, device, eps=0.5, min_samples=5, sample_fraction=1.0):\n",
    "    \"\"\"\n",
    "    Применяет DBSCAN к dense признакам, извлечённым из всего датасета, и вычисляет:\n",
    "      - silhouette score,\n",
    "      - Davies-Bouldin index,\n",
    "      - Calinski-Harabasz score.\n",
    "    \"\"\"\n",
    "    features = extract_dense_features_global(model, dataloader, device, sample_fraction)\n",
    "    print(f\"Total extracted features: {features.shape[0]}\")\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    cluster_labels = dbscan.fit_predict(features)\n",
    "    \n",
    "    unique_clusters = set(cluster_labels)\n",
    "    if -1 in unique_clusters:\n",
    "        unique_clusters.remove(-1)\n",
    "    \n",
    "    if len(unique_clusters) < 2:\n",
    "        print(\"Not enough clusters (>=2 required) in global clustering.\")\n",
    "        return None, None, None, cluster_labels\n",
    "    \n",
    "    sil = silhouette_score(features, cluster_labels)\n",
    "    db_index = davies_bouldin_score(features, cluster_labels)\n",
    "    ch_score = calinski_harabasz_score(features, cluster_labels)\n",
    "    return sil, db_index, ch_score, cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dense_features_per_image(model, image, device):\n",
    "    \"\"\"\n",
    "    Извлекает dense признаки для одного изображения, возвращает массив размерности [H*W, C].\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0).to(device)  # [1, 3, H, W]\n",
    "        feat_map = model.backbone(image)[-1]     # [1, C, H, W]\n",
    "        feat_map = F.normalize(feat_map, p=2, dim=1)\n",
    "        _, C, H, W = feat_map.shape\n",
    "        features = feat_map.view(1, C, -1).permute(0, 2, 1).contiguous().view(-1, C)\n",
    "    return features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dense_features_per_image(model, image, device):\n",
    "    \"\"\"\n",
    "    Извлекает dense признаки для одного изображения, возвращает массив размерности [H*W, C].\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0).to(device)  # [1, 3, H, W]\n",
    "        feat_map = model.backbone(image)[-1]     # [1, C, H, W]\n",
    "        feat_map = F.normalize(feat_map, p=2, dim=1)\n",
    "        _, C, H, W = feat_map.shape\n",
    "        features = feat_map.view(1, C, -1).permute(0, 2, 1).contiguous().view(-1, C)\n",
    "    return features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_image_clustering_dbscan(model, dataloader, device, eps=0.5, min_samples=5):\n",
    "    \"\"\"\n",
    "    Для каждого изображения выполняет DBSCAN кластеризацию dense признаков и вычисляет метрики:\n",
    "      silhouette score, Davies-Bouldin и Calinski-Harabasz.\n",
    "    Усредняет метрики по всем изображениям, где удалось получить >=2 кластера.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sil_scores, db_scores, ch_scores = [], [], []\n",
    "    image_count = 0\n",
    "    for images, _ in dataloader:\n",
    "        for i in range(images.size(0)):\n",
    "            features = extract_dense_features_per_image(model, images[i], device)\n",
    "            dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            labels = dbscan.fit_predict(features)\n",
    "            unique_clusters = set(labels)\n",
    "            if -1 in unique_clusters:\n",
    "                unique_clusters.remove(-1)\n",
    "            if len(unique_clusters) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                sil = silhouette_score(features, labels)\n",
    "                db = davies_bouldin_score(features, labels)\n",
    "                ch = calinski_harabasz_score(features, labels)\n",
    "                sil_scores.append(sil)\n",
    "                db_scores.append(db)\n",
    "                ch_scores.append(ch)\n",
    "                image_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error on image {image_count}: {e}\")\n",
    "                continue\n",
    "    if len(sil_scores) == 0:\n",
    "        print(\"No image produced enough clusters for per-image evaluation.\")\n",
    "        return None, None, None\n",
    "    avg_sil = np.mean(sil_scores)\n",
    "    avg_db = np.mean(db_scores)\n",
    "    avg_ch = np.mean(ch_scores)\n",
    "    print(f\"Processed {image_count} images. Avg Silhouette: {avg_sil:.4f}, Avg Davies-Bouldin: {avg_db:.4f}, Avg Calinski-Harabasz: {avg_ch:.4f}\")\n",
    "    return avg_sil, avg_db, avg_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(source_dir, train_dir, val_dir, train_ratio=0.8, extensions=('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "    \"\"\"\n",
    "    Разбивает файлы из source_dir на тренировочный и валидационный наборы и копирует их в train_dir и val_dir.\n",
    "    \n",
    "    Args:\n",
    "        source_dir (str): путь к исходной папке с изображениями.\n",
    "        train_dir (str): путь к папке, куда будут скопированы тренировочные изображения.\n",
    "        val_dir (str): путь к папке, куда будут скопированы валидационные изображения.\n",
    "        train_ratio (float): доля изображений, которые пойдут в тренировочный набор.\n",
    "        extensions (tuple): допустимые расширения файлов.\n",
    "    \"\"\"\n",
    "    # Создаем папки, если их нет\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    # Получаем список файлов с нужными расширениями\n",
    "    all_files = [f for f in os.listdir(source_dir) if f.lower().endswith(extensions)]\n",
    "    print(f\"Найдено {len(all_files)} изображений в папке {source_dir}.\")\n",
    "    \n",
    "    # Перемешиваем список случайным образом\n",
    "    random.shuffle(all_files)\n",
    "    \n",
    "    # Определяем индекс для разбиения\n",
    "    split_index = int(len(all_files) * train_ratio)\n",
    "    train_files = all_files[:split_index]\n",
    "    val_files = all_files[split_index:]\n",
    "    \n",
    "    # Копируем файлы в соответствующие папки\n",
    "    for filename in train_files:\n",
    "        shutil.copy(os.path.join(source_dir, filename), os.path.join(train_dir, filename))\n",
    "    \n",
    "    for filename in val_files:\n",
    "        shutil.copy(os.path.join(source_dir, filename), os.path.join(val_dir, filename))\n",
    "    \n",
    "    print(f\"Тренировочный набор: {len(train_files)} изображений.\")\n",
    "    print(f\"Валидационный набор: {len(val_files)} изображений.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Пользовательский датасет для папки с изображениями.\n",
    "    Все файлы с расширениями .png, .jpg, .jpeg, .bmp будут загружены.\n",
    "    Так как данные не размечены, возвращается фиктивная метка (0).\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): путь к папке с изображениями.\n",
    "            transform (callable, optional): Трансформации, которые применяются к изображению.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [\n",
    "            os.path.join(root_dir, file)\n",
    "            for file in os.listdir(root_dir)\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))\n",
    "        ]\n",
    "        self.image_files = sorted(self.image_files)  # Опционально сортируем файлы\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # Возвращаем изображение и фиктивную метку\n",
    "        return image, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                      std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'dataset/turbine'\n",
    "train_folder = 'dataset/turbine_train'\n",
    "val_folder = 'dataset/turbine_val'\n",
    "\n",
    "# split_dataset(source_dir=data_folder, train_dir=train_folder, val_dir=val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolderDataset(root_dir=train_folder, transform=base_transform)\n",
    "val_dataset   = ImageFolderDataset(root_dir=val_folder, transform=base_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.compute_mean_std import compute_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_mean_std(train_dataset, 32, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "task = Task.init(project_name=\"SSL_Detection\", task_name=\"PixPro Training \")\n",
    "\n",
    "# imagenet_model = timm.create_model('resnet18', pretrained=True, features_only=True)\n",
    "model = PixPro(backbone_name='resnet18').to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 100\n",
    "val_interval = 5\n",
    "save_interval = 10\n",
    "eps = 0.5\n",
    "min_samples = 5\n",
    "sample_fraction = 0.2\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    avg_loss = train_pixpro(model, train_loader, optimizer, device, epoch, augment_fn=batch_augmentations)\n",
    "    task.get_logger().report_scalar(\"Training\", \"Loss\", iteration=epoch, value=avg_loss)\n",
    "    \n",
    "    # Проводим валидацию каждые val_interval эпох\n",
    "    if epoch % val_interval == 0:\n",
    "        print(f\"--- Validation at Epoch {epoch} ---\")\n",
    "        # Глобальная кластеризация DBSCAN\n",
    "        global_results = global_clustering_dbscan(model, val_loader, device, eps, min_samples, sample_fraction)\n",
    "        if global_results[0] is not None:\n",
    "            sil, db_index, ch_score, _ = global_results\n",
    "            print(f\"Global DBSCAN -> Silhouette: {sil:.4f}, Davies-Bouldin: {db_index:.4f}, Calinski-Harabasz: {ch_score:.4f}\")\n",
    "            task.get_logger().report_scalar(\"Clustering_Sil\", \"Global_Silhouette\", iteration=epoch, value=sil)\n",
    "            task.get_logger().report_scalar(\"Clustering_DB\", \"Global_Davies_Bouldin\", iteration=epoch, value=db_index)\n",
    "            task.get_logger().report_scalar(\"Clustering_CH\", \"Global_Calinski_Harabasz\", iteration=epoch, value=ch_score)\n",
    "        else:\n",
    "            print(\"Global clustering did not produce enough clusters.\")\n",
    "        \n",
    "        # Кластеризация по отдельности для каждого изображения\n",
    "        per_img_results = per_image_clustering_dbscan(model, val_loader, device, eps, min_samples)\n",
    "        if per_img_results[0] is not None:\n",
    "            avg_sil, avg_db, avg_ch = per_img_results\n",
    "            print(f\"Per-image DBSCAN -> Avg Silhouette: {avg_sil:.4f}, Avg Davies-Bouldin: {avg_db:.4f}, Avg Calinski-Harabasz: {avg_ch:.4f}\")\n",
    "            task.get_logger().report_scalar(\"Clustering_Sil\", \"PerImage_Silhouette\", iteration=epoch, value=avg_sil)\n",
    "            task.get_logger().report_scalar(\"Clustering_DB\", \"PerImage_Davies_Bouldin\", iteration=epoch, value=avg_db)\n",
    "            task.get_logger().report_scalar(\"Clustering_CH\", \"PerImage_Calinski_Harabasz\", iteration=epoch, value=avg_ch)\n",
    "        else:\n",
    "            print(\"Per-image clustering did not produce metrics for enough images.\")\n",
    "    \n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        path_to_ckpt = f'checkpoint_epoch_{epoch}.pth'\n",
    "        torch.save(model.state_dict(), path_to_ckpt)\n",
    "        task.upload_artifact(name=\"model_checkpoint\", artifact_object=path_to_ckpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
